{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d1396d-26de-463f-863d-f3619744d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/project/6105902/shougan/balance-budget\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2e06b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 12-08 16:50:07 [__init__.py:244] Automatically detected platform cuda.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6105902/shougan/balance-budget/venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/project/6105902/shougan/balance-budget/venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shougan/projects/aip-fredashi/shougan/balance-budget/tuning\n"
     ]
    }
   ],
   "source": [
    "from tuning.inference.vllm_utils import load_vlm_model, make_vllm_call\n",
    "from vllm import SamplingParams\n",
    "from tuning.utils.utils import apply_chat_template, chat_template_func\n",
    "from tuning.config import IFEVAL_OUTPUTS_DIR, RESPONSES_FILENAME\n",
    "from tuning.utils.gpt_utils import save_responses\n",
    "from datasets import load_from_disk, DatasetDict\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a7f893d-f1de-41a8-b0a6-7d147ef2d1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_logp(llm, prompt_messages, response_message=None):\n",
    "    tokenizer = llm.get_tokenizer()\n",
    "    tokenizer = chat_template_func(tokenizer) # add chatML\n",
    "    \n",
    "    if response_message:\n",
    "        prompt_str = tokenizer.apply_chat_template(prompt_messages, tokenize=False, add_generation_prompt=True)\n",
    "        prompt_ids = tokenizer.encode(prompt_str)\n",
    "\n",
    "        messages_with_response = prompt_messages + response_message\n",
    "        full_text = tokenizer.apply_chat_template(messages_with_response, tokenize=False, add_generation_prompt=False)\n",
    "        full_input_ids = tokenizer.encode(full_text)\n",
    "\n",
    "        sampling_params = SamplingParams(\n",
    "            prompt_logprobs=100000,   \n",
    "            max_tokens=1,        \n",
    "            temperature=0.0,\n",
    "            stop=[],\n",
    "        )\n",
    "\n",
    "        outputs = llm.generate([full_text], sampling_params)\n",
    "        output = outputs[0]\n",
    "\n",
    "        prompt_logprobs = output.prompt_logprobs\n",
    "        \n",
    "        response_log_probabilities = []\n",
    "        for i in range(len(prompt_ids), len(full_input_ids)):\n",
    "            token_i = full_input_ids[i] \n",
    "            logprob_dict = prompt_logprobs[i] # each generated token has its own logP dictionary\n",
    "            \n",
    "            if token_i in logprob_dict:\n",
    "                response_log_probabilities.append(logprob_dict[token_i].logprob)\n",
    "            else:\n",
    "                print(f\"CANNOT FIND THE TOKEN {token_i} at {i}\")\n",
    "                response_log_probabilities.append(-100.0) \n",
    "\n",
    "        return response_message, sum(response_log_probabilities)\n",
    "\n",
    "\n",
    "    else:\n",
    "        sampling_params = SamplingParams(\n",
    "            prompt_logprobs = 1,\n",
    "            temperature=0,\n",
    "            logprobs=1,\n",
    "            max_tokens=4096,\n",
    "        )\n",
    "        prompt_str = tokenizer.apply_chat_template(prompt_messages, tokenize=False, add_generation_prompt=True)\n",
    "        outputs = llm.generate(prompt_str, sampling_params)\n",
    "\n",
    "        output = outputs[0].outputs[0]\n",
    "            \n",
    "        response_log_probabilities = []\n",
    "        for logprob in output.logprobs:\n",
    "            token_id = list(logprob.keys())[0] # get the id of the single chosen token \n",
    "            response_log_probabilities.append(logprob[token_id].logprob)\n",
    "            \n",
    "        total_logp = np.sum(response_log_probabilities)\n",
    "\n",
    "        return output.text, total_logp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3fa4505-845b-4fd2-81d5-63d06870e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama3-8B\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e93ded86-0579-4a82-8384-fa445706231c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/shougan/projects/aip-fredashi/shougan/balance-budget/tuning/models/llama3-8B\n",
      "Using GPU memory utilization: 0.8\n",
      "INFO 12-08 12:56:11 [config.py:841] This model supports multiple tasks: {'embed', 'reward', 'classify', 'generate'}. Defaulting to 'generate'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-08 12:56:11 [config.py:3368] Downcasting torch.float32 to torch.bfloat16.\n",
      "INFO 12-08 12:56:11 [config.py:1472] Using max model len 131072\n",
      "INFO 12-08 12:56:14 [config.py:2285] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "WARNING 12-08 12:56:15 [__init__.py:2662] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reason: CUDA is initialized\n",
      "INFO 12-08 12:56:22 [__init__.py:244] Automatically detected platform cuda.\n",
      "INFO 12-08 12:56:24 [core.py:526] Waiting for init message from front-end.\n",
      "INFO 12-08 12:56:24 [core.py:69] Initializing a V1 LLM engine (v0.9.2) with config: model='/home/shougan/projects/aip-fredashi/shougan/balance-budget/tuning/models/llama3-8B', speculative_config=None, tokenizer='/home/shougan/projects/aip-fredashi/shougan/balance-budget/tuning/models/llama3-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/home/shougan/projects/aip-fredashi/shougan/balance-budget/tuning/models/llama3-8B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "INFO 12-08 12:56:25 [parallel_state.py:1076] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "WARNING 12-08 12:56:25 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 12-08 12:56:25 [gpu_model_runner.py:1770] Starting to load model /home/shougan/projects/aip-fredashi/shougan/balance-budget/tuning/models/llama3-8B...\n",
      "INFO 12-08 12:56:25 [gpu_model_runner.py:1775] Loading model from scratch...\n",
      "INFO 12-08 12:56:26 [cuda.py:284] Using Flash Attention backend on V1 engine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/7 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  14% Completed | 1/7 [00:01<00:09,  1.62s/it]\n",
      "Loading safetensors checkpoint shards:  29% Completed | 2/7 [00:03<00:08,  1.68s/it]\n",
      "Loading safetensors checkpoint shards:  43% Completed | 3/7 [00:05<00:06,  1.73s/it]\n",
      "Loading safetensors checkpoint shards:  57% Completed | 4/7 [00:06<00:05,  1.76s/it]\n",
      "Loading safetensors checkpoint shards:  71% Completed | 5/7 [00:08<00:03,  1.76s/it]\n",
      "Loading safetensors checkpoint shards:  86% Completed | 6/7 [00:10<00:01,  1.77s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:11<00:00,  1.49s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 7/7 [00:11<00:00,  1.63s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-08 12:56:37 [default_loader.py:272] Loading weights took 11.45 seconds\n",
      "INFO 12-08 12:56:38 [gpu_model_runner.py:1801] Model loading took 15.0006 GiB and 11.904924 seconds\n",
      "INFO 12-08 12:56:50 [backends.py:508] Using cache directory: /home/shougan/.cache/vllm/torch_compile_cache/30aefafaa6/rank_0_0/backbone for vLLM's torch.compile\n",
      "INFO 12-08 12:56:50 [backends.py:519] Dynamo bytecode transform time: 12.04 s\n",
      "INFO 12-08 12:56:57 [backends.py:155] Directly load the compiled graph(s) for shape None from the cache, took 6.674 s\n",
      "INFO 12-08 12:56:58 [monitor.py:34] torch.compile takes 12.04 s in total\n",
      "INFO 12-08 12:56:59 [gpu_worker.py:232] Available KV cache memory: 19.20 GiB\n",
      "INFO 12-08 12:56:59 [kv_cache_utils.py:716] GPU KV cache size: 157,296 tokens\n",
      "INFO 12-08 12:56:59 [kv_cache_utils.py:720] Maximum concurrency for 131,072 tokens per request: 1.20x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:18<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-08 12:57:18 [gpu_model_runner.py:2326] Graph capturing finished in 18 secs, took 0.56 GiB\n",
      "INFO 12-08 12:57:18 [core.py:172] init engine (profile, create kv cache, warmup model) took 40.45 seconds\n"
     ]
    }
   ],
   "source": [
    "llm, _ = load_vlm_model(model_name, max_logprobs = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7647b1c5-7654-45c1-b45f-a6ba87f17f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a helpful assistant who is an expert at responding to prompts by carefully following the given instructions', 'role': 'system'}, {'content': 'As a financial advisor with expertise in the insurance sector, create an informative guide on \"The Evolution of Life Insurance Policies in the United States\" for your clients in Brentwood, Tennessee. Your guide should meet the following constraints:\\n\\n- The guide must be structured into three distinct paragraphs.\\n- Within each paragraph, include at least two keywords from the following list: \"policyholder,\" \"beneficiary,\" \"underwriting,\" \"premium,\" \"coverage.\"\\n- Ensure that each paragraph contains at least one sentence where the letter \\'i\\' appears at least 8 times.\\n- Conclude your guide with a summary in the form of two bullet points, each point containing the word \"insurance\" at least once.', 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/project/6105902/shougan/balance-budget/tuning/data/datasets/sft-tuluif\"\n",
    "full_dataset = load_from_disk(dataset_path)\n",
    "data_point = full_dataset[\"train\"][1]\n",
    "\n",
    "prompt_message = prompt_message = [data_point['messages'][0], data_point['messages'][1]] #index 0 and 1 is system and user question\n",
    "ground_truth_answer = [data_point['messages'][2]]\n",
    "print(prompt_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce671e4c-cc2a-41ef-b51a-0e2f211fe7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2115243596ca4b9f98d0c4b8cd97e81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d89b16d4ab4589b016a3ce7a3dbd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|                                                 | 0/1 [00:00<?, ?it/s, est. speed inpâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "greedy_answer, greedy_logp = get_response_logp(llm, prompt_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "101c9665-0d69-4a89-a5a1-f94275e626b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Evolution of Life Insurance Policies in the United States\n",
      "Life insurance has been a crucial component of financial planning for individuals and families in the United States for over two centuries. Over time, life insurance policies have evolved to meet the changing needs and preferences of policyholders. In this guide, we will explore the history of life insurance policies in the United States, focusing on key milestones and developments that have shaped the industry.\n",
      "\n",
      "The Early Years: 18th and 19th Centuries\n",
      "The first life insurance policies in the United States were introduced in the late 18th century. These policies were primarily designed to provide financial protection for families in the event of the death of the breadwinner. The early policies were often simple and straightforward, with a fixed premium and a death benefit paid to the beneficiary upon the policyholder's death.\n",
      "\n",
      "The 20th Century: Growth and Innovation\n",
      "The 20th century saw significant growth and innovation in the life insurance industry. One of the most important developments was the introduction of group life insurance policies, which allowed employers to offer life insurance coverage to their employees as a benefit. This helped to expand the reach of life insurance to a wider range of individuals.\n",
      "\n",
      "Another major development was the introduction of term life insurance policies, which provided coverage for a specific period of time, typically 10, 20, or 30 years. Term life insurance policies were often more affordable than whole life insurance policies, making them a popular choice for many policyholders.\n",
      "\n",
      "The 21st Century: Modernization and Technology\n",
      "In recent years, the life insurance industry has continued to evolve and modernize. One of the most significant developments has been the use of technology to streamline the underwriting process and make it more efficient. This has allowed insurers to offer more competitive rates and better service to policyholders.\n",
      "\n",
      "Another important trend has been the rise of digital platforms and online tools that make it easier for individuals to research and purchase life insurance policies. This has helped to increase transparency and accessibility in the industry, making it easier for consumers to find the coverage they need.\n",
      "\n",
      "Conclusion\n",
      "The evolution of life insurance policies in the United States has been driven by a combination of economic, social, and technological factors. Over time, life insurance policies have become more sophisticated and tailored to meet the needs of policyholders. Today, life insurance remains an important part of financial planning for individuals and families, providing peace of mind and financial security in the event of unexpected events.\n",
      "-171.5168519429667\n"
     ]
    }
   ],
   "source": [
    "print(greedy_answer)\n",
    "print(greedy_logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a9a619d0-0395-4b15-b538-6bee1c046bde",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[126]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ground_answer, ground_logp = get_response_logp(\u001b[43mllm\u001b[49m, prompt_message, response_message=ground_truth_answer)\n",
      "\u001b[31mNameError\u001b[39m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "ground_answer, ground_logp = get_response_logp(llm, prompt_message, response_message=ground_truth_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a11de555-7c4d-4790-8ec6-444a9c6c0b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': '**The Evolution of Life Insurance Policies in the United States**\\n\\nLife insurance has undergone significant changes over the years, adapting to the evolving needs of policyholders and the regulatory environment. Initially, life insurance policies were simple agreements between the insurer and the policyholder, offering basic coverage to ensure financial security for beneficiaries. Over time, the underwriting process has become more sophisticated, allowing insurers to better assess risk and tailor premiums to individual circumstances. This evolution has made life insurance more accessible and affordable, while providing policyholders with more options to suit their specific needs.\\n\\nThe role of underwriting in life insurance has expanded significantly, with advances in technology enabling insurers to gather and analyze more data than ever before. Underwriting now involves assessing a range of factors, from medical history to lifestyle habits, to determine the appropriate coverage and premium for each policyholder. Beneficiaries stand to gain from these advancements, as more precise underwriting leads to policies that better match the risk profile of the insured, ensuring that the coverage provided is both adequate and cost-effective. With these innovations, insurers can offer competitive premiums while maintaining their commitment to providing security for beneficiaries.\\n\\nAs life insurance policies have evolved, so too have the options available to policyholders and the benefits they provide. Modern life insurance products offer a variety of coverage options, from term life to whole life and universal life, each designed to meet different financial goals and needs. Policyholders can now customize their insurance plans, adding riders for additional coverage or flexible premiums to suit their changing circumstances. These innovations have significantly increased the importance of life insurance as a financial planning tool, offering both protection and investment opportunities for policyholders and their beneficiaries.\\n\\n- Life insurance has evolved to offer more personalized coverage and competitive premiums.\\n- Modern life insurance products provide flexible options, enhancing their role in financial planning.', 'role': 'assistant'}]\n",
      "-5885.421590294049\n"
     ]
    }
   ],
   "source": [
    "print(ground_answer)\n",
    "print(ground_logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a06dcdf6-8eaa-4a31-b999-fae7a8899ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def get_response_logp_transformers(model, tokenizer, prompt_messages, response_message = False):\n",
    "    \n",
    "    if response_message: # get logP of existing response\n",
    "        prompt_str = tokenizer.apply_chat_template(prompt_messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "        prompt_ids = tokenizer.encode(prompt_str, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "        messages_with_response = prompt_messages + response_message\n",
    "        full_text = tokenizer.apply_chat_template(messages_with_response, tokenize=False, add_generation_prompt=False)\n",
    "        full_input_ids = tokenizer.encode(full_text, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(full_input_ids)\n",
    "            logits = outputs.logits\n",
    "        response_start_index = len(prompt_ids[0])\n",
    "        print(f\"Shape of prompt_id {prompt_ids.shape}, {response_start_index}\")\n",
    "\n",
    "        relevant_logits = logits[0, response_start_index - 1:-1, :]\n",
    "    \n",
    "        response_ids = full_input_ids[0, response_start_index:]\n",
    "        \n",
    "        log_probs = torch.nn.functional.log_softmax(relevant_logits, dim=-1) # softmax and log the logits\n",
    "    \n",
    "        response_log_probs = []\n",
    "    \n",
    "        for i in range(len(response_ids)) :\n",
    "            token_id_i = response_ids[i].item()\n",
    "            log_prob_i = log_probs[i, token_id_i].item()\n",
    "            response_log_probs.append(log_prob_i)\n",
    "    \n",
    "        return response_message, sum(response_log_probs)\n",
    "    else:\n",
    "        prompt_ids = tokenizer.apply_chat_template(\n",
    "                        prompt_messages,\n",
    "                        tokenize=False, \n",
    "                        add_generation_prompt = True\n",
    "        )\n",
    "\n",
    "        prompt_ids = tokenizer.encode(prompt_ids, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generated_output = model.generate(\n",
    "                prompt_ids,\n",
    "                max_new_tokens=4096,\n",
    "                num_beams = 1,\n",
    "                do_sample=False,  # Greedy decoding\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True # need .score\n",
    "            )\n",
    "            \n",
    "        generated_ids = generated_output.sequences[0, prompt_ids.shape[-1]:] # exclude the prompt_ids\n",
    "        \n",
    "        response_log_probs = []\n",
    "        for i, token_id in enumerate(generated_ids):\n",
    "            logits_at_i = generated_output.scores[i][0] \n",
    "            log_probs_at_i = torch.nn.functional.log_softmax(logits_at_i, dim=-1)\n",
    "            log_prob_i = log_probs_at_i[token_id].item()\n",
    "            response_log_probs.append(log_prob_i)\n",
    "        \n",
    "        generated_text = tokenizer.decode(generated_ids)\n",
    "        return generated_text, sum(response_log_probs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b8d68e9-9c5d-466b-92c0-28bb8906a658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf64ea19fb6545aeae3266cb13d16dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Will map <|im_end|> to EOS = <|end_of_text|>.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "hf_path = f\"/project/6105902/shougan/balance-budget/tuning/models/{model_name}\"\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(hf_path, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "hf_tokenizer = AutoTokenizer.from_pretrained(hf_path)\n",
    "hf_tokenizer = chat_template_func(hf_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d0f3612-5ce9-4c1e-88d9-b9ba0f2ea609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of prompt_id torch.Size([1, 188]), 188\n"
     ]
    }
   ],
   "source": [
    "ground_response, ground_truth_logp_hf = get_response_logp_transformers(hf_model, hf_tokenizer, prompt_message, response_message = ground_truth_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e453ade4-9f1f-4286-9059-0376154ab98e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-451.28200340270996\n",
      "[{'content': '**The Evolution of Life Insurance Policies in the United States**\\n\\nLife insurance has undergone significant changes over the years, adapting to the evolving needs of policyholders and the regulatory environment. Initially, life insurance policies were simple agreements between the insurer and the policyholder, offering basic coverage to ensure financial security for beneficiaries. Over time, the underwriting process has become more sophisticated, allowing insurers to better assess risk and tailor premiums to individual circumstances. This evolution has made life insurance more accessible and affordable, while providing policyholders with more options to suit their specific needs.\\n\\nThe role of underwriting in life insurance has expanded significantly, with advances in technology enabling insurers to gather and analyze more data than ever before. Underwriting now involves assessing a range of factors, from medical history to lifestyle habits, to determine the appropriate coverage and premium for each policyholder. Beneficiaries stand to gain from these advancements, as more precise underwriting leads to policies that better match the risk profile of the insured, ensuring that the coverage provided is both adequate and cost-effective. With these innovations, insurers can offer competitive premiums while maintaining their commitment to providing security for beneficiaries.\\n\\nAs life insurance policies have evolved, so too have the options available to policyholders and the benefits they provide. Modern life insurance products offer a variety of coverage options, from term life to whole life and universal life, each designed to meet different financial goals and needs. Policyholders can now customize their insurance plans, adding riders for additional coverage or flexible premiums to suit their changing circumstances. These innovations have significantly increased the importance of life insurance as a financial planning tool, offering both protection and investment opportunities for policyholders and their beneficiaries.\\n\\n- Life insurance has evolved to offer more personalized coverage and competitive premiums.\\n- Modern life insurance products provide flexible options, enhancing their role in financial planning.', 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth_logp_hf)\n",
    "print(ground_response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f51dcd3-dd6c-4e6a-a1a7-18d60a57e673",
   "metadata": {},
   "outputs": [],
   "source": [
    " greedy_response_hf, greedy_logp_hf = get_response_logp_transformers(hf_model, hf_tokenizer, prompt_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c62bd6b-9d16-49fb-8b90-018c78f7f75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.790224567012956\n",
      "As a financial advisor with expertise in the insurance sector, create an informative guide on \"The Evolution of Life Insurance Policies in the United States\" for your clients in Brentwood, Tennessee. Your guide should meet the following constraints:\n",
      "\n",
      "- The guide must be structured into three distinct paragraphs.\n",
      "- Within each paragraph, include at least two keywords from the following list: \"policyholder,\" \"beneficiary,\" \"underwriting,\" \"premium,\" \"coverage.\"\n",
      "- Ensure that each paragraph contains at least one sentence where the letter 'i' appears at least 8 times.\n",
      "- Conclude your guide with a summary in the form of two bullet points, each point containing the word \"insurance\" at least once.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(greedy_logp_hf)\n",
    "print(greedy_response_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8718ccbb-665b-4a2d-bfc9-5d72e0aaa6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_str = hf_tokenizer.apply_chat_template(prompt_message, tokenize = False, add_generation_prompt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b76fe23f-63e3-4a78-bf42-fc6420ce1ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant who is an expert at responding to prompts by carefully following the given instructions<|im_end|>\n",
      "<|im_start|>user\n",
      "As a financial advisor with expertise in the insurance sector, create an informative guide on \"The Evolution of Life Insurance Policies in the United States\" for your clients in Brentwood, Tennessee. Your guide should meet the following constraints:\n",
      "\n",
      "- The guide must be structured into three distinct paragraphs.\n",
      "- Within each paragraph, include at least two keywords from the following list: \"policyholder,\" \"beneficiary,\" \"underwriting,\" \"premium,\" \"coverage.\"\n",
      "- Ensure that each paragraph contains at least one sentence where the letter 'i' appears at least 8 times.\n",
      "- Conclude your guide with a summary in the form of two bullet points, each point containing the word \"insurance\" at least once.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9cf2773-8789-4ac3-ab4a-73af8d0e2e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_ids = hf_tokenizer.encode(prompt_str, return_tensors=\"pt\").to(hf_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "238fd43e-912f-4ba6-9396-8e275ad3bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    generated_output = hf_model.generate(\n",
    "        prompt_ids[:,1:], \n",
    "        max_new_tokens = 4096, \n",
    "        num_beams = 1, \n",
    "        do_sample = False, \n",
    "        return_dict_in_generate = True, \n",
    "        output_scores = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46cc84f3-5059-4eb2-a8d0-eb6c40ae4a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 232])\n"
     ]
    }
   ],
   "source": [
    "generated_ids = generated_output.sequences[0, ]\n",
    "print(generated_output.sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a88e7ba2-ba21-4e29-a316-00ee5d3ead70",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = hf_tokenizer.decode(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50090043-c083-4c6f-9f93-bb5c88e412a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant who is an expert at responding to prompts by carefully following the given instructions<|im_end|>\n",
      "<|im_start|>user\n",
      "As a financial advisor with expertise in the insurance sector, create an informative guide on \"The Evolution of Life Insurance Policies in the United States\" for your clients in Brentwood, Tennessee. Your guide should meet the following constraints:\n",
      "\n",
      "- The guide must be structured into three distinct paragraphs.\n",
      "- Within each paragraph, include at least two keywords from the following list: \"policyholder,\" \"beneficiary,\" \"underwriting,\" \"premium,\" \"coverage.\"\n",
      "- Ensure that each paragraph contains at least one sentence where the letter 'i' appears at least 8 times.\n",
      "- Conclude your guide with a summary in the form of two bullet points, each point containing the word \"insurance\" at least once.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "You are a skilled assistant who excels at following instructions and meeting constraints. Your guide will provide valuable insights into the evolution of life insurance policies in the United States, helping your clients make informed decisions about their financial future.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
